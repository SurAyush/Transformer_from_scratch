{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer normalization\n",
    "# To implement Layer Normalization on a tensor with shape (B,T,C) we need to calculate the mean and variance across C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4960,  1.2352,  1.2042, -0.8860],\n",
       "         [ 0.8651, -1.2128,  0.0826,  1.1599],\n",
       "         [-0.2576,  0.0948, -1.2240,  0.8942]],\n",
       "\n",
       "        [[ 0.3061,  0.1813, -1.4799, -0.5743],\n",
       "         [-0.5189,  0.2496, -0.5847,  0.9014],\n",
       "         [ 0.5438, -0.1844,  0.8721,  1.5228]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2644],\n",
       "         [ 0.2237],\n",
       "         [-0.1232]],\n",
       "\n",
       "        [[-0.3917],\n",
       "         [ 0.0119],\n",
       "         [ 0.6886]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = x.mean(-1, keepdim=True)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9318],\n",
       "         [0.8428],\n",
       "         [0.5781]],\n",
       "\n",
       "        [[0.5082],\n",
       "         [0.3713],\n",
       "         [0.3781]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = ((x - mean) ** 2).mean(-1, keepdim=True)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5\n",
    "x_norm = (x-mean) / torch.sqrt(var + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7877,  1.0057,  0.9736, -1.1917],\n",
       "         [ 0.6986, -1.5647, -0.1537,  1.0198],\n",
       "         [-0.1769,  0.2866, -1.4478,  1.3381]],\n",
       "\n",
       "        [[ 0.9789,  0.8037, -1.5265, -0.2561],\n",
       "         [-0.8709,  0.3902, -0.9790,  1.4597],\n",
       "         [-0.2354, -1.4196,  0.2984,  1.3566]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(torch.nn.Module):\n",
    "    def __init__(self, features, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.gamma = torch.nn.Parameter(torch.ones(features))           # scale parameter\n",
    "        self.beta = torch.nn.Parameter(torch.zeros(features))           # shift parameter\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = ((x - mean) ** 2).mean(-1, keepdim=True)\n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.gamma * x_norm + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LayerNorm(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7877,  1.0057,  0.9736, -1.1917],\n",
       "         [ 0.6986, -1.5647, -0.1537,  1.0198],\n",
       "         [-0.1769,  0.2866, -1.4478,  1.3381]],\n",
       "\n",
       "        [[ 0.9789,  0.8037, -1.5265, -0.2561],\n",
       "         [-0.8709,  0.3902, -0.9790,  1.4597],\n",
       "         [-0.2354, -1.4196,  0.2984,  1.3566]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd\n",
      "ac\n"
     ]
    }
   ],
   "source": [
    "dic = {'a': 1, 'b': 2}\n",
    "vocab = set(dic.keys())\n",
    "w = [\"ab\", \"cd\",\"ac\",\"b\",\"ba\"]\n",
    "for i in w:\n",
    "    if any(ch not in vocab for ch in i):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
